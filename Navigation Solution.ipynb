{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b081764",
   "metadata": {},
   "source": [
    "## Navigation Solution\n",
    "Below is my solution of the drl Nanodegree project navigation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe05d9c",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abab397c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Other imports are in agent and the model files\n",
    "from unityagents import UnityEnvironment\n",
    "from agent import Agent\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359b855a",
   "metadata": {},
   "source": [
    "### Initalize the enviroment\n",
    "Set this to your file path for the Unity Enviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9191f83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_pth = \"C:/Users/skycr/Udacity_Projects/Value-based-methods/p1_navigation/Banana_Windows_x86_64\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48404f45",
   "metadata": {},
   "source": [
    "Obtain the enviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "550a165a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: BananaBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 37\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "#initalize the enviroment\n",
    "env = UnityEnvironment(file_name=file_pth + \"/Banana.exe\")\n",
    "    \n",
    "#obtain the enviroment brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df060198",
   "metadata": {},
   "source": [
    "Obtain action and state spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef5678bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain number of actions available\n",
    "action_size = brain.vector_action_space_size\n",
    "\n",
    "# obtain the state space \n",
    "state_size = brain.vector_observation_space_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d727226",
   "metadata": {},
   "source": [
    "### Have the selected agent work in the enviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d42db2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DQN(agent, num_episodes=1000, target_score=13.0):\n",
    "    \"\"\"\"\"\"\n",
    "    \n",
    "    agent = agent #initalize agent object\n",
    "    \n",
    "    highest_avg_score = 0 #initalize the highest score variable\n",
    "    solved_episode = 0 #The final episode that the agent completed its enviroment on\n",
    "\n",
    "    #Training Loop\n",
    "    for episode in range(1, num_episodes + 1):\n",
    "        env_info = env.reset(train_mode=True)[brain_name] #reset enviroment\n",
    "        state = env_info.vector_observations[0] # gather current state\n",
    "        score = 0 #initalize score variable\n",
    "\n",
    "        while True:       \n",
    "            action = agent.action(state) #agents interacts with its enviroment\n",
    "            env_info = env.step(action)[brain_name] #send the action to the enviroment\n",
    "            next_state = env_info.vector_observations[0] #get the next state\n",
    "            reward = env_info.rewards[0] #get agents reward\n",
    "            done = env_info.local_done[0] #check if the episode is done\n",
    "\n",
    "            #update the agent based on the experince\n",
    "            agent.step(state, action, reward, next_state, done)\n",
    "\n",
    "            #add reward to score\n",
    "            score += reward\n",
    "\n",
    "            #transition to next state\n",
    "            state = next_state\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "                \n",
    "        #if on first episode give a starter value to highest_avg_score\n",
    "        if episode == 1:\n",
    "            highest_avg_score = score\n",
    "        else:\n",
    "            highest_avg_score = max(highest_avg_score, (highest_avg_score * (episode - 1) + score) / episode)\n",
    "            \n",
    "        # Check if the agent has solved the environment\n",
    "        if highest_avg_score >= target_score and not solved_episode:\n",
    "            solved_episode = episode\n",
    "\n",
    "        agent.epsilon_update()\n",
    "        print(f\"\\rEpisode: {episode}/{num_episodes} - Score: {score} - Highest Avg Score: {highest_avg_score:.2f} - current eps: {agent.eps}\", end=\"\")\n",
    "        \n",
    "        #Check if the agent has solved its enviroment and end the training loop\n",
    "        if solved_episode:\n",
    "            break\n",
    "    print(f\"Solved in {solved_episode} episodes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2a7ba3",
   "metadata": {},
   "source": [
    "#### Changable Variables\n",
    "Below are the Variables that you are free to change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc3b5933",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_episodes = 1000\n",
    "#set the problems target score\n",
    "target_score = 13.0\n",
    "#set the seed min and maximum\n",
    "seed_min = 0\n",
    "seed_max = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ca0f5d",
   "metadata": {},
   "source": [
    "#### Non-changable Variabels\n",
    "Do not change the variables listed below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f91fd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = random.randint(seed_min, seed_max)\n",
    "Basic_Agent = Agent(action_size, state_size, seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d0c0e0",
   "metadata": {},
   "source": [
    "#### Select preferred agent\n",
    "Input your wanted agent, you only have to input numbers. (there is only basic agent for now)\n",
    "\n",
    "`1` - Basic_Agent\n",
    "\n",
    "(Plan to add more in the future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e43917c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "user = int(input())\n",
    "\n",
    "#Basic Agent is the deafult if wrong input\n",
    "if (user == 1):\n",
    "    agent = Basic_Agent\n",
    "else:\n",
    "    print(\"WRONG INPUT!\")\n",
    "    print(\"Selecting Basic_Agent as deafult.\")\n",
    "    agent = Basic_Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d04e49",
   "metadata": {},
   "source": [
    "### Running the DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5eff8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 887/1000 - Score: 1.0 - Highest Avg Score: 1.39 - current eps: 0.169351918887157923"
     ]
    }
   ],
   "source": [
    "DQN(agent, num_episodes, target_score)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707a1652",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07fef48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
